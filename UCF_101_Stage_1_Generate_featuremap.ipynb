{"cells":[{"cell_type":"markdown","source":["# Last test data : 2022-04-10"],"metadata":{"id":"OLYPDSNFMD5r"}},{"cell_type":"markdown","source":["## Step1. Download and extract UCF101 Data"],"metadata":{"id":"pt4zwMCWdlpl"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71057,"status":"ok","timestamp":1649466368543,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"id":"fduc0vBUc1zb","outputId":"c4f2fbab-a286-452b-eb05-3dd908dbbe58"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-09 01:04:57--  https://www.crcv.ucf.edu/data/UCF101/UCF101.rar\n","Resolving www.crcv.ucf.edu (www.crcv.ucf.edu)... 132.170.214.127\n","Connecting to www.crcv.ucf.edu (www.crcv.ucf.edu)|132.170.214.127|:443... connected.\n","WARNING: cannot verify www.crcv.ucf.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n","  Unable to locally verify the issuer's authority.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6932971618 (6.5G) [application/rar]\n","Saving to: ‘UCF101.rar’\n","\n","UCF101.rar          100%[===================>]   6.46G  89.3MB/s    in 71s     \n","\n","2022-04-09 01:06:08 (93.4 MB/s) - ‘UCF101.rar’ saved [6932971618/6932971618]\n","\n"]}],"source":["! wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF101/UCF101.rar\n","% rm -rf sample_data\n","! mkdir UCF101\n","! unrar x \"/content/UCF101.rar\" \"/content/UCF101\"\n","\n","\n","# Screen Cleaning, there are too many files to display.\n","from IPython.display import clear_output \n","clear_output()"]},{"cell_type":"markdown","source":["## Step2. [Option] Delete unused video files\n","You do not need to run this step to create a feature map for the entire video file. If you run the code below, only 11 videos are left. Feature extraction takes several hours depending on the model for transfer learning.\n","\n","Therefore, to test only, execute the code below. It also takes about 20-30 minutes to generate a feature map for 11 video files."],"metadata":{"id":"v9u9LbiVdqTG"}},{"cell_type":"code","source":["% rm -rf /content/UCF101/UCF-101/YoYo\n","% rm -rf /content/UCF101/UCF-101/WritingOnBoard\n","% rm -rf /content/UCF101/UCF-101/WallPushups\n","% rm -rf /content/UCF101/UCF-101/WalkingWithDog\n","% rm -rf /content/UCF101/UCF-101/VolleyballSpiking\n","% rm -rf /content/UCF101/UCF-101/UnevenBars\n","% rm -rf /content/UCF101/UCF-101/Typing\n","% rm -rf /content/UCF101/UCF-101/TrampolineJumping\n","% rm -rf /content/UCF101/UCF-101/ThrowDiscus\n","% rm -rf /content/UCF101/UCF-101/TennisSwing\n","% rm -rf /content/UCF101/UCF-101/TaiChi\n","% rm -rf /content/UCF101/UCF-101/TableTennisShot\n","% rm -rf /content/UCF101/UCF-101/Swing\n","% rm -rf /content/UCF101/UCF-101/Surfing\n","% rm -rf /content/UCF101/UCF-101/SumoWrestling\n","% rm -rf /content/UCF101/UCF-101/StillRings\n","% rm -rf /content/UCF101/UCF-101/SoccerPenalty\n","% rm -rf /content/UCF101/UCF-101/SoccerJuggling\n","% rm -rf /content/UCF101/UCF-101/SkyDiving\n","% rm -rf /content/UCF101/UCF-101/Skijet\n","% rm -rf /content/UCF101/UCF-101/Skiing\n","% rm -rf /content/UCF101/UCF-101/SkateBoarding\n","% rm -rf /content/UCF101/UCF-101/Shotput\n","% rm -rf /content/UCF101/UCF-101/ShavingBeard\n","% rm -rf /content/UCF101/UCF-101/SalsaSpin\n","% rm -rf /content/UCF101/UCF-101/Rowing\n","% rm -rf /content/UCF101/UCF-101/RopeClimbing\n","% rm -rf /content/UCF101/UCF-101/RockClimbingIndoor\n","% rm -rf /content/UCF101/UCF-101/Rafting\n","% rm -rf /content/UCF101/UCF-101/PushUps\n","% rm -rf /content/UCF101/UCF-101/Punch\n","% rm -rf /content/UCF101/UCF-101/PullUps\n","% rm -rf /content/UCF101/UCF-101/PommelHorse\n","% rm -rf /content/UCF101/UCF-101/PoleVault\n","% rm -rf /content/UCF101/UCF-101/PlayingViolin\n","% rm -rf /content/UCF101/UCF-101/PlayingTabla\n","% rm -rf /content/UCF101/UCF-101/PlayingSitar\n","% rm -rf /content/UCF101/UCF-101/PlayingPiano\n","% rm -rf /content/UCF101/UCF-101/PlayingGuitar\n","% rm -rf /content/UCF101/UCF-101/PlayingFlute\n","% rm -rf /content/UCF101/UCF-101/PlayingDhol\n","% rm -rf /content/UCF101/UCF-101/PlayingDaf\n","% rm -rf /content/UCF101/UCF-101/PlayingCello\n","% rm -rf /content/UCF101/UCF-101/PizzaTossing\n","% rm -rf /content/UCF101/UCF-101/ParallelBars\n","% rm -rf /content/UCF101/UCF-101/Nunchucks\n","% rm -rf /content/UCF101/UCF-101/MoppingFloor\n","% rm -rf /content/UCF101/UCF-101/Mixing\n","% rm -rf /content/UCF101/UCF-101/MilitaryParade\n","% rm -rf /content/UCF101/UCF-101/Lunges\n","% rm -rf /content/UCF101/UCF-101/LongJump\n","% rm -rf /content/UCF101/UCF-101/Knitting\n","% rm -rf /content/UCF101/UCF-101/Kayaking\n","% rm -rf /content/UCF101/UCF-101/JumpingJack\n","% rm -rf /content/UCF101/UCF-101/JumpRope\n","% rm -rf /content/UCF101/UCF-101/JugglingBalls\n","% rm -rf /content/UCF101/UCF-101/JavelinThrow\n","% rm -rf /content/UCF101/UCF-101/IceDancing\n","% rm -rf /content/UCF101/UCF-101/HulaHoop\n","% rm -rf /content/UCF101/UCF-101/HorseRiding\n","% rm -rf /content/UCF101/UCF-101/HorseRace\n","% rm -rf /content/UCF101/UCF-101/HighJump\n","% rm -rf /content/UCF101/UCF-101/HeadMassage\n","% rm -rf /content/UCF101/UCF-101/HandstandWalking\n","% rm -rf /content/UCF101/UCF-101/HandstandPushups\n","% rm -rf /content/UCF101/UCF-101/Hammering\n","% rm -rf /content/UCF101/UCF-101/HammerThrow\n","% rm -rf /content/UCF101/UCF-101/Haircut\n","% rm -rf /content/UCF101/UCF-101/GolfSwing\n","% rm -rf /content/UCF101/UCF-101/FrontCrawl\n","% rm -rf /content/UCF101/UCF-101/FrisbeeCatch\n","% rm -rf /content/UCF101/UCF-101/CliffDiving\n","% rm -rf /content/UCF101/UCF-101/CricketBowling\n","% rm -rf /content/UCF101/UCF-101/CricketShot\n","% rm -rf /content/UCF101/UCF-101/CuttingInKitchen\n","% rm -rf /content/UCF101/UCF-101/Diving\n","% rm -rf /content/UCF101/UCF-101/Drumming\n","% rm -rf /content/UCF101/UCF-101/Fencing\n","% rm -rf /content/UCF101/UCF-101/FieldHockeyPenalty\n","% rm -rf /content/UCF101/UCF-101/FloorGymnastics\n","% rm -rf /content/UCF101/UCF-101/Billiards\n","% rm -rf /content/UCF101/UCF-101/BlowDryHair\n","% rm -rf /content/UCF101/UCF-101/BlowingCandles\n","% rm -rf /content/UCF101/UCF-101/BodyWeightSquats\n","% rm -rf /content/UCF101/UCF-101/Bowling\n","% rm -rf /content/UCF101/UCF-101/BoxingPunchingBag\n","% rm -rf /content/UCF101/UCF-101/BoxingSpeedBag\n","% rm -rf /content/UCF101/UCF-101/BreastStroke\n","% rm -rf /content/UCF101/UCF-101/BrushingTeeth\n","% rm -rf /content/UCF101/UCF-101/CleanAndJerk"],"metadata":{"id":"6icmceT7oR4s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step3. Build mirror directories\n","The directory structure to save the feature map is made the same as the directory structure of the video file."],"metadata":{"id":"ouWfFMAQd2z8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIerP29JMxST"},"outputs":[],"source":["import os\n","\n","inputpath = '/content/UCF101/UCF-101/'\n","outputpath_1 = './UCF101_Inception_64_frame/'\n","\n","for dirpath, dirnames, filenames in os.walk(inputpath):\n","    structure = os.path.join(outputpath_1, dirpath[len(inputpath):])\n","    if not os.path.isdir(structure):\n","        os.mkdir(structure)\n","    else:\n","        print(\"Folder does already exits!\")\n","\n","outputpath_2 = './UCF101_MobilenetV2_64_frame/'\n","\n","for dirpath, dirnames, filenames in os.walk(inputpath):\n","    structure = os.path.join(outputpath_2, dirpath[len(inputpath):])\n","    if not os.path.isdir(structure):\n","        os.mkdir(structure)\n","    else:\n","        print(\"Folder does already exits!\")\n","\n","outputpath_3 = './UCF101_Resnet152_64_frame/'\n","\n","for dirpath, dirnames, filenames in os.walk(inputpath):\n","    structure = os.path.join(outputpath_3, dirpath[len(inputpath):])\n","    if not os.path.isdir(structure):\n","        os.mkdir(structure)\n","    else:\n","        print(\"Folder does already exits!\")\n"]},{"cell_type":"markdown","metadata":{"id":"gDTFFMaRdnhL"},"source":["## Step4. Generate feature map - Inception\n","\n","Create a featuremap using transfer learning. It generates 64 images uniformly from video and creates a featuremap for each image using ImageNet, MobileNet, and ResNet.\n","\n","For Inception dataframe generation it takes more than 2 hours\n","\n","2:11:42"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":953513,"status":"ok","timestamp":1649470721734,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"id":"eDU-vujMcBsa","outputId":"2443b745-2eae-4638-dd59-6ef7a0466d6d"},"outputs":[{"output_type":"stream","name":"stderr","text":["5997it [15:51,  6.30it/s]\n"]}],"source":["import tensorflow as tf\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tqdm\n","from sklearn.preprocessing import LabelBinarizer\n","\n","import sys\n","\n","\n","BASE_PATH = './UCF101_Inception_64_frame'\n","VIDEOS_PATH = os.path.join('/content/UCF101/UCF-101', '**','*.avi')\n","SEQUENCE_LENGTH = 64\n","\n","def frame_generator():\n","    video_paths = tf.io.gfile.glob(VIDEOS_PATH)\n","    np.random.shuffle(video_paths)\n","    for video_path in video_paths:\n","        frames = []\n","        cap = cv2.VideoCapture(video_path)\n","        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n","        current_frame = 0\n","\n","        label = os.path.basename(os.path.dirname(video_path))\n","\n","        max_images = SEQUENCE_LENGTH\n","        while True:\n","            success, frame = cap.read()\n","            if not success:\n","                break\n","\n","            if current_frame % sample_every_frame == 0:\n","                # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n","                frame = frame[:, :, ::-1]\n","                img = tf.image.resize(frame, (299, 299))\n","                img = tf.keras.applications.inception_v3.preprocess_input(\n","                    img)\n","                max_images -= 1\n","                yield img, video_path\n","\n","            if max_images == 0:\n","                break\n","            current_frame += 1\n","\n","# `from_generator` might throw a warning, expected to disappear in upcoming versions:\n","# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#for_example_2\n","dataset = tf.data.Dataset.from_generator(frame_generator,\n","             output_types=(tf.float32, tf.string),\n","             output_shapes=((299, 299, 3), ()))\n","\n","dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","inception_v3 = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n","\n","x = inception_v3.output\n","\n","# We add Average Pooling to transform the feature map from\n","# 8 * 8 * 2048 to 1 x 2048, as we don't need spatial information\n","pooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n","\n","feature_extraction_model = tf.keras.Model(inception_v3.input, pooling_output)\n","\n","current_path = None\n","all_features = []\n","\n","for img, batch_paths in tqdm.tqdm(dataset):\n","    batch_features = feature_extraction_model(img)\n","    batch_features = tf.reshape(batch_features, \n","                              (batch_features.shape[0], -1))\n","    \n","    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n","        if path != current_path and current_path is not None:\n","            \n","            # print(current_path)\n","            # print(current_path.decode())\n","            \n","            output_path = current_path.decode().replace('.avi', '.npy')\n","            output_path = output_path.replace('UCF101/UCF-101', 'UCF101_Inception_64_frame')\n","            # print(output_path)\n","\n","            np.save(output_path, all_features)\n","            all_features = []\n","            \n","            # import sys\n","            # sys.exit()s\n","\n","        current_path = path\n","        all_features.append(features)\n"]},{"cell_type":"markdown","metadata":{"id":"sokCwow2zmpn"},"source":["## Generate feature map - MobileNet\n","\n","For mobilenet_v2 dataframe generation it takes around 1:46:05"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":749489,"status":"ok","timestamp":1649467374281,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"id":"9LjvwwkJVk-D","outputId":"a80c86ad-5e37-4ba4-cb3c-8bcb5ff8193e"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","9420800/9406464 [==============================] - 0s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["5997it [12:17,  8.13it/s]\n"]}],"source":["import tensorflow as tf\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tqdm\n","from sklearn.preprocessing import LabelBinarizer\n","\n","import sys\n","\n","\n","BASE_PATH = './UCF101_MobilenetV2_64_frame'\n","VIDEOS_PATH = os.path.join('/content/UCF101/UCF-101', '**','*.avi')\n","SEQUENCE_LENGTH = 64\n","\n","def frame_generator():\n","    video_paths = tf.io.gfile.glob(VIDEOS_PATH)\n","    np.random.shuffle(video_paths)\n","    for video_path in video_paths:\n","        frames = []\n","        cap = cv2.VideoCapture(video_path)\n","        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n","        current_frame = 0\n","\n","        label = os.path.basename(os.path.dirname(video_path))\n","\n","        max_images = SEQUENCE_LENGTH\n","        while True:\n","            success, frame = cap.read()\n","            if not success:\n","                break\n","\n","            if current_frame % sample_every_frame == 0:\n","                # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n","                frame = frame[:, :, ::-1]\n","                img = tf.image.resize(frame, (299, 299))\n","                img = tf.keras.applications.mobilenet_v2.preprocess_input(\n","                    img)\n","                max_images -= 1\n","                yield img, video_path\n","\n","            if max_images == 0:\n","                break\n","            current_frame += 1\n","\n","# `from_generator` might throw a warning, expected to disappear in upcoming versions:\n","# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#for_example_2\n","dataset = tf.data.Dataset.from_generator(frame_generator,\n","             output_types=(tf.float32, tf.string),\n","             output_shapes=((299, 299, 3), ()))\n","\n","dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","mobilenet_v2 = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet')\n","\n","x = mobilenet_v2.output\n","\n","# We add Average Pooling to transform the feature map from\n","# 8 * 8 * 2048 to 1 x 2048, as we don't need spatial information\n","pooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n","\n","feature_extraction_model = tf.keras.Model(mobilenet_v2.input, pooling_output)\n","\n","current_path = None\n","all_features = []\n","\n","for img, batch_paths in tqdm.tqdm(dataset):\n","    batch_features = feature_extraction_model(img)\n","    batch_features = tf.reshape(batch_features, \n","                              (batch_features.shape[0], -1))\n","    \n","    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n","        if path != current_path and current_path is not None:\n","            \n","            # print(\"\\nOOO PATH \",current_path)\n","            # print(\"CUR PATH :\", current_path.decode())\n","            \n","            output_path = current_path.decode().replace('UCF101/UCF-101', 'UCF101_MobilenetV2_64_frame')\n","            output_path = output_path.replace('.avi', '.npy')\n","\n","            # print(\"OUT PAT :\", output_path)\n","\n","            np.save(output_path, all_features)\n","            all_features = []\n","            \n","            # import sys\n","            # sys.exit()\n","\n","\n","        current_path = path\n","        all_features.append(features)\n"]},{"cell_type":"markdown","source":["## Generate feature map - ResNet 152\n","\n","It takes more than 3 hours."],"metadata":{"id":"nlxInZQpfMY0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"vCktwWe3XnxD","outputId":"fcd4d9b8-7709-4b09-90b1-50258fbb427c","executionInfo":{"status":"error","timestamp":1649469557528,"user_tz":-540,"elapsed":5323,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["4it [00:01,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["b'/content/UCF101/UCF-101/Basketball/v_Basketball_g10_c01.avi'\n","CUR PATH : /content/UCF101/UCF-101/Basketball/v_Basketball_g10_c01.avi\n","OUT PATH : /content/UCF101_Resnet152_64_frame/Basketball/v_Basketball_g10_c01.npy\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["import tensorflow as tf\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tqdm\n","from sklearn.preprocessing import LabelBinarizer\n","\n","import sys\n","\n","\n","BASE_PATH = './UCF101_Resnet152_64_frame'\n","VIDEOS_PATH = os.path.join('/content/UCF101/UCF-101', '**','*.avi')\n","SEQUENCE_LENGTH = 64\n","\n","def frame_generator():\n","    video_paths = tf.io.gfile.glob(VIDEOS_PATH)\n","    np.random.shuffle(video_paths)\n","    for video_path in video_paths:\n","        frames = []\n","        cap = cv2.VideoCapture(video_path)\n","        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n","        current_frame = 0\n","\n","        label = os.path.basename(os.path.dirname(video_path))\n","\n","        max_images = SEQUENCE_LENGTH\n","        while True:\n","            success, frame = cap.read()\n","            if not success:\n","                break\n","\n","            if current_frame % sample_every_frame == 0:\n","                # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n","                frame = frame[:, :, ::-1]\n","                img = tf.image.resize(frame, (299, 299))\n","                img = tf.keras.applications.resnet.preprocess_input(\n","                    img)\n","                max_images -= 1\n","                yield img, video_path\n","\n","            if max_images == 0:\n","                break\n","            current_frame += 1\n","\n","# `from_generator` might throw a warning, expected to disappear in upcoming versions:\n","# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#for_example_2\n","dataset = tf.data.Dataset.from_generator(frame_generator,\n","             output_types=(tf.float32, tf.string),\n","             output_shapes=((299, 299, 3), ()))\n","\n","dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","resnet_152 = tf.keras.applications.ResNet152(include_top=False, weights='imagenet')\n","\n","x = resnet_152.output\n","\n","# We add Average Pooling to transform the feature map from\n","# 8 * 8 * 2048 to 1 x 2048, as we don't need spatial information\n","pooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n","\n","feature_extraction_model = tf.keras.Model(resnet_152.input, pooling_output)\n","\n","current_path = None\n","all_features = []\n","\n","for img, batch_paths in tqdm.tqdm(dataset):\n","    batch_features = feature_extraction_model(img)\n","    batch_features = tf.reshape(batch_features, \n","                              (batch_features.shape[0], -1))\n","    \n","    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n","        if path != current_path and current_path is not None:\n","            \n","            # print(current_path)\n","            # print(\"CUR PATH :\", current_path.decode())\n","            \n","            output_path = current_path.decode().replace('UCF101/UCF-101', 'UCF101_Resnet152_64_frame')\n","            output_path = output_path.replace('.avi', '.npy')\n","            # print(\"OUT PATH :\", output_path)\n","            \n","            np.save(output_path, all_features)\n","            all_features = []\n","            \n","            # import sys\n","            # sys.exit()\n","\n","        current_path = path\n","        all_features.append(features)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"UCF_101_Generate_Feature_Map.ipynb","provenance":[],"authorship_tag":"ABX9TyMHYVAChmcrCWASE0k4EIKA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}